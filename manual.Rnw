
\documentclass[12pt]{article}


<<eval=FALSE,echo=FALSE>>=
##Make sure these packages are installed before trying to compile
install.packages(c("ggplot2", "gridExtra","RColorBrewer","knitr","beeswarm","UsingR","tidyr","rmarkdown","clinfun","RVAideMemoire"))
source("http://www.bioconductor.org/biocLite.R")
biocLite("BiocStyle")
@



<<knitr, echo=FALSE, results="hide">>=
library("knitr")
opts_chunk$set(tidy=FALSE,dev="png",fig.show="as.is",
               fig.width=10,fig.height=6,
               message=FALSE,eval=TRUE,warning=FALSE,echo=TRUE)
@ 

<<style, eval=TRUE, echo=F, results="asis">>=
BiocStyle::latex()
@
\usepackage{ifthen} 
\usepackage{xcolor,colortbl}
\newboolean{includethis} 
\setboolean{includethis}{true}

\newcommand{\ifinclude}[1]{\ifthenelse{\boolean{includethis}}{#1}{}} 



\title{Further Statistical Analysis using R}
\author{Mark Dunning, Matt Eldridge and Sarah Vowler \thanks{Acknowledgements: Sarah Dawson}}
\date{Last Document revision: \today}
\begin{document}


\maketitle
\tableofcontents

\section{Course Introduction}

\centerline{\includegraphics[width=4cm,height=4cm]{images/fisher.jpg}}

\textit{"To consult the statistician after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of."}. R.A. Fisher, 1938\\


The goals of statistical methods could be summarised as follows:
\begin{itemize}
\item{drawing conclusions about a population by analysing data on just a sample;}
\item{evaluating the uncertainty in these conclusions; and,}
\item{designing the sampling approach so that valid and accurate conclusions can be made from the data collected.}
\end{itemize}

The statistical approach used is dependent on the data type. In this document we will describe methods for comparing multiple groups (\textbf{ANOVA} (analysis of variance), and \textbf{non-parametric} alternatives), and \textbf{Linear Regression}. We will assume you are already familiar with methods to perform one-sample or two-sample tests, as described in our \href{http://bioinformatics-core-shared-training.github.io/IntroductionToStats/manual.pdf}{\color{blue}{Introductory Statistics}} course. After describing the assumptions of each test, we will give a worked example in R.

\subsection{Exploratory Analysis}
Before conducting a formal analysis of our data, it is always a good idea to run some exploratory checks of the data: 
\begin{itemize}
\item{To check that the data has been read in or entered correctly; }
\item{To identify any outlying values and if there is reason to question their validity, exclude them or investigate them further; }
\item{To see the distribution of the observations and whether the planned analyses are appropriate.}
\end{itemize}
It's always a good idea to calculate some summary statistics for your data, such as the mean and standard deviation, or the median and inter-quartile range if your data is skewed. You should also consider whether there may be outliers in your data (but do not remove them from the analysis without good reason) or whether there may be missing data. Summary statistics were covered in detail in our \href{http://bioinformatics-core-shared-training.github.io/IntroductionToStats/manual.pdf}{\color{blue}{Introductory Statistics}} course.

\subsection{Statistical Tests - basic setup}

There are four key steps in every statistical test:
\begin{itemize}
\item{1 Formulate a \textbf{null hypothesis}, H$_0$. This is the working hypothesis that we wish to disprove.}
\item{2. Under the assumption that the \textbf{null hypothesis} is true, calculate a \textbf{test statistic} from the data.}
\item{3. Determine whether the \textbf{test statistic} is more extreme than we would expect under the \textbf{null hypothesis}, i.e. look at the \textbf{p-value}.}
\item{4. Reject or do not reject the \textbf{null hypothesis}.}
\end{itemize}
As the name suggests, the null hypothesis typically corresponds to a \textbf{null} effect. 

For example, there is \textbf{no difference} in the measurements in group 1 compared with group 2. A small p-value indicates that the probability of observing such a test statistic as small under the assumption that the null hypothesis is true. If the p-value is below a pre-specified \textbf{significance level}, then this is a \textbf{significant result} and, we would conclude, there is evidence to reject the null hypothesis.

The \textbf{significance level} is most commonly set at 5\% and may also be thought of as the \textbf{false positive rate}. That is, there is a 5\% chance that the null hypothesis is true for data-sets with test statistics corresponding to p-values of less than 0.05 – i.e. we may wrongly reject the null hypothesis when the null hypothesis is true (false positive).

<<echo=FALSE,fig.show='asis',fig.height=5,fig.width=10,warning=FALSE,message=FALSE>>=

library(ggplot2)
x     = rnorm(10000, 0, 1)
sd <- sd(x)
me <- mean(x)

dat <- data.frame(x=x)
rects <- data.frame(xstart = c(-1.96,1.96), xend = c(-Inf,Inf),col=c("A","A"))

normdist <- ggplot() +   geom_histogram(data = dat, aes(x))+  geom_rect(data = rects, aes(xmin = xstart, xmax = xend, ymin = -Inf, ymax = Inf),alpha=0.4,fill="yellow") + ylab("") + xlab("") + theme(legend.position="none")
            
normdist
@

Equally, we may make \textbf{false negative} conclusions from statistical tests. In other words, we may not reject the null hypothesis when the null hypothesis is, in fact, not true. When referring to the false negative rate, statisticians usually refer to \textbf{power}, which is 1-false negative rate. 

The \textbf{power} of a statistical test will depend on:

\begin{itemize}
\item{The \textbf{significance level} - a 5\% test of significance will have a greater chance of rejecting the null than a 1\% test because the strength of evidence required for rejection is less.}
\item{The \textbf{sample size} – the larger the sample size, the more accurate our estimates (e.g. of the mean) which means we can differentiate between the null and alternative hypotheses more clearly.}
\item{The \textbf{size of the difference or effect} we wish to detect – bigger differences (i.e. alternative hypotheses) are easier to detect than smaller differences.}
\item{The \textbf{variability}, or standard deviation, of the observations – the more variable our observations, the less accurate our estimates which means it is more difficult to differentiate between the null and alternative hypotheses.}
\end{itemize}


\begin{table}[h]

\centering

\begin{tabular}{| l | l | l|}
   \hline
  & \textbf{Null hypothesis does not hold} &\textbf{Null hypothesis holds} \\
  \hline
  \textbf{Reject null hypothesis} & {\cellcolor{Orchid}Correct \textit{True Positive}} & {\cellcolor{CadetBlue}Wrong \textit{False positive}} \\
  \textbf{Do no reject null hypothesis} & {\cellcolor{CadetBlue}Wrong \textit{False negative}} & {\cellcolor{Orchid}Correct \textit{True negative}} \\
  \hline
\end{tabular}
\caption{Error definitions}
\label{errors}
\end{table}

\section{R Introduction}

To install R visit \href{www.r-project.org}{\color{blue}{www.r-project.org}}. In the 'Getting Started' box half-way down the page follow the 'download R' link. On the next page choose the appropriate operating system for your computer from the three 'Download R for...' options. 

Following this link will start the installation of R. If you get a security warning select 'Run'. Follow the directions in the install wizard to install R. We haven chosen to run {\tt R} through the popular \href{https://www.rstudio.com/products/RStudio/#Desktop}{\color{blue}{Rstudio}} interface, which you will also need to install. The version of R used to write this manual is {\color{red}{\Sexpr{paste(R.Version()$major, R.Version()$minor,sep=".")}}}. Please bear in mind that the version number you download may be different as new versions are released yearly. 


This manual, and the accompanying practical will assume some famililarity with the R statistical language. In particular, you should be familiar with the following concepts:

\begin{itemize}
\item{Using the RStudio program}
\item{Setting your working directory}
\item{Creating variables and basic object types; in particular vectors and data frames}
\item{Using built-in R functions}
\item{Using R to get help on functions}
\item{Subset operations for vectors and data frames using the [] notation}
\item{Reading tabular data into R}
\item{Basic plots; scatter plots, boxplot and histogram}
\end{itemize}

Several Online videos are available that cover this materials. For example

\begin{itemize}
\item{\href{http://shop.oreilly.com/product/0636920034834.do}{\color{blue}{http://shop.oreilly.com/product/0636920034834.do}}}
\item{\href{http://blog.revolutionanalytics.com/2012/12/coursera-videos.html}{\color{blue}{http://blog.revolutionanalytics.com/2012/12/coursera-videos.html}}}
\item{\href{http://bitesizebio.com/webinar/20600/beginners-introduction-to-r-statistical-software}{\color{blue}{http://bitesizebio.com/webinar/20600/beginners-introduction-to-r-statistical-software}}}
\end{itemize}

\subsection{R packages Used}

In order to run the examples in this manual, and the practical, you will need to execute the following command in R to install the required packages.
<<eval=FALSE>>=
install.packages(c("tidyr","beeswarm","RColorBrewer","clinfun","RVAideMemoire"))
@

\subsection{Formatting data for Statistical Testing in R}
\label{dataManip}
Before conducting a statistical test in R we often need to manipulate our data into a particular format. If you are familiar with working with numerical data in Excel (or similar), then you probably represent your data in tabular format. See Table \ref{messy.eg} for an example taken from the seminal 'Tidy Data' paper by Hadley Wickham \cite{tidyr:paper}.

<<echo=FALSE,results='asis'>>=
library(xtable)
messy <- data.frame(Name = c("John Smith","Jane Doe","Mary Johnson"),treatmenta = c("-",4,6),treatmentb=c(18,1,7))
print(xtable(messy,label="messy.eg",caption="An imaginary dataset in human-readable format."))
@

Table \ref{messy.eg} is easy for humans to comprehend; we can easily scan the table and identify that John Smith has a measurement of 18 for 'treatmenta' and no observation for 'treatmentb'. However, it is not very efficient for computers to deal with data in this format. For the majority of statistical testing that is performed in R, we think of the observations in our datasets as being explained by a series of factors, or explanatory variables. For example, in our imaginary dataset we have a measurement for each patient that belongs to either treatment group a, or treatment group b. Thus, the factor in this case would be treatment. Table \ref{tidy.eg} shows the same dataset, but in a \textit{'tidy'} format with \textit{variables} as columns and each row forming a different \textit{observation}. Sometimes this is also referred to as \textit{long} data, as opposed to the \textit{wide} format of the original table.

<<echo=FALSE,results='asis'>>=

tidy <- data.frame(name = c("Jane Doe","Jane Doe", "John Smith", "John Smith", "Mary Johnson","Mary Johnson"), treatment = rep(c("a","b"),3), n = c(4,1,NA,18,6,7))

print(xtable(tidy,label="tidy.eg",caption="The same imaginary dataset, but in tidy format."))

@

Several options exist in R to transform our data in this manner; such as the \Rfunction{stack} function from base R, to the \CRANpkg{reshape} and \CRANpkg{reshape2} packages. However, we will describe the \CRANpkg{tidyr} package, which is the evolution of \CRANpkg{reshape} and \CRANpkg{reshape2} and is nicely integrated with other advanced manipulation tools such as \CRANpkg{dplyr} and \CRANpkg{ggplot2}. 

We will now illustrate the how to transform our imaginary dataset into a suitable format for statistical analysis using \CRANpkg{tidyr}. The goal of such an operation is to take the \Rcode{treatmenta} and \Rcode{treatmentb} columns and create two separate columns; one which indicates whether a particular observation was made for treatment a or treatmentb, and the corresponding values. In the language of \CRANpkg{tidyr}, we say the the treatment variable is a \textit{key}.

<<>>=
messy <- data.frame(Name = c("John Smith","Jane Doe","Mary Johnson"),
                    treatmenta = c(NA,4,6),treatmentb=c(18,1,7))
@

The function to be used is called \Rfunction{gather} \footnote{Don't forget that you can get help on this function using \Rcode{?gather}}. The function is sometimes able to take a data frame as input and 'guess' what the tidy form of that dataset should look like. Finer control is possible, such as specifying column names in the output. In this example, we specify that we want a column in the output called \Rcode{'treatment'} for our new variable (the key), and \Rcode{'n'} for the corresponding values. The final argument is for specifying which columns in the input data are to be decomposed.

<<>>=
library(tidyr)
tidy <- gather(messy,treatment,n,treatmenta,treatmentb)
tidy
@

Note that we can use shortcuts to select columns, such as selecting all columns in the range \Rcode{treatmenta} to \Rcode{treatmentb}, or all columns except \Rcode{Name}. You should see that these give the same result. 
<<eval=FALSE>>=
gather(messy,treatment,n,treatmenta:treatmentb)
gather(messy,treatment,n,-Name)

@

With our data in this format, we can now specifiy various formulas using the tilde ($\sim$) syntax. You may have already seen the following syntax which will plot a boxplot with explanatory variable \Rcode{treatment} on the x-axis, and observations \Rcode{n} on the y-axis.

<<>>=
boxplot(tidy$n~tidy$treatment)
@

As we often have the variable and values that we wish to plot in the same data frame, there are a couple of shortcuts to avoid using the \$ syntax (which is a bit in-elegant). Firstly, functions such as \Rfunction{boxplot} and other statistical testing functions (e.g. \Rfunction{t.test}) have a \Rcode{data} argument. This allows the name of a data frame to be specified and the variables can be referred to by name.

<<eval=FALSE>>=
boxplot(n~treatment,data=tidy)
@

The \Rfunction{with} function also performs the same task;

<<eval=FALSE>>=
with(tidy, boxplot(n~treatment))
@


\section{Comparing Multiple Groups}

ANOVA stands for \textit{an}alysis \textit{o}f \textit{v}ariance. There are three main types of ANOVA: one-way, two-way and repeated measures. In this course our main focus will be on the one-way ANOVA.

\subsection{One-way ANOVA}
\label(oneWayAnova)
The two-sample t-test is useful when we have just two groups of continuous data to compare, but when we want to compare more than two groups a one-way ANOVA can be used to simultaneously compare all groups rather than carrying out several individual two-sample t-tests.  The main advantage of doing this is that it reduces the number of tests being carried out, meaning that the type I error rate (the probability of seeing a significant result just by chance) does not become inflated. 

A one-way ANOVA compares group means by partitioning the variation in the data into \textbf{between group} variance and \textbf{within group variance} (see Table \ref{anova-table}). 

\begin{table}[h]

\centering

\begin{tabular}{| l | l | l|l|l|}
\hline
\textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sum of Squares} & \textbf{Mean Squares} & $F_{k-1,N-k}$ \\
\hline
Between groups & $k - 1$ &  $BSS = \sum_{k}^{i=1} n_iy^2_i - \frac{T^2}{N}$ & $S^2_B = \frac{BSS}{k -1}$ & \\
\hline
Within groups & $N - k$ & $WSS = S - \sum_{i=1}^{k} n_iy^2_i $ & $S^2_W = \frac{WSS}{N-k}$ & \\
\hline
Total & $N - 1 $ & TSS = BSS + WSS & & $\frac{S^2_B}{S^2_W}$\\
\hline
\end{tabular}
\caption{One-way ANOVA table}
\label{anova-table}
\end{table}

The between group variance is divided by the within group variance to give an F statistic. This tells us the ratio of between group variation to within group variation. A large F-value implies that there are significant differences between groups and conversely a small F-value implies there are not significant differences between groups. Giving this a little bit of thought, the idea becomes more intuitive:

\begin{itemize}
\item{If the variance within groups is small, but between groups the variance is very large, we can infer that there are likely to be differences between groups. Following this theory, the F statistic is calculated by dividing the between group variation by the within group variation. So in this scenario, we divide a large number by a comparatively small number and this leaves us with a large(ish) number for our F statistic, corresponding to a small p-value.}
\item{If the variance within groups is large, but between groups the variance is also large, it is more difficult to know whether the groups truly differ in their mean value. In this scenario, the F statistic is calculated by dividing a large number by another large number - depending on the relative size of these two large numbers we may be left with a large or small number for our F statistic. The same is true when the variance within and between groups are both small.}
\item{Finally, if the variance within group is large, but between groups the variance is very small, we can infer that there are unlikely to be differences between groups. In this scenario, the F statistic is calculated by dividing a small number by a large number and this will result in a small(ish) number for our F statistic, corresponding to a large p-value.}
\end{itemize}
Luckily, you won’t need to do the calculations from Table \ref{anova-table} by hand as R will do these all for you, but it’s good to have an appreciation of what the test is actually doing in the background.

Obviously the outcome of the one-way ANOVA depends on the data available. If there is high variation in the data, a much larger sample will be needed to detect a difference between groups. Likewise, if we are interested in detecting very small differences between groups a larger sample size will be required. 

\subsubsection{ANOVA assumptions}
\label{anova-assumptions}
There are several assumptions behind the one-way ANOVA:

\begin{itemize}
\item{Normally distributed response (assessed for each group separately)}
\item{Approximately equal variance across the groups}
\item{Independent observations}
\end{itemize}
The main assumption is that the distribution of the response variable should be normally distributed for each group being compared. This can be assessed prior to fitting the ANOVA by constructing a histogram of the response variable for each group being compared. This can also be assessed after fitting the ANOVA by constructing a normal probability plot of the residuals (sometimes called a Q-Q plot).

Another important assumption is that there is approximately equal variance across the groups being compared. This assumption is important because of the way the F-test in the ANOVA uses the pooled variance across groups. If one group has a much larger variance than another group, the results of the F-test may not be valid. The equal variance assumption can be assessed using either Bartlett's or Levene's test (REMEMBER! this adds to the multiple testing problem), or visually using a histogram plotted separately for each group. 

A third assumption of the one-way ANOVA is the independence of observations. There is no easy way of assessing independence, so a lot of people overlook this assumption. However, a little thought about where the data comes from and how it was collected can give us a good indication of whether the observations are independent or not. Things like taking observations from related individuals or having multiple measurements per subject will cause the independence assumption to be invalid.

If the F-test provides a significant result, we may be interested in making comparisons between pairs of groups to identify where the difference lies and estimate the effect size. This can be done by using unpaired two-sample t-tests. If we wish to make multiple comparisons we must be careful to adjust for multiple testing and R has several options to do this. There are several different types of multiple-testing adjustment than can be made, each suiting different types of comparisons. These are discussed in more detail in the section \ref{choosing-the-correct-post-test}.  

\subsubsection{Choosing the correct post-test}
\label{choosing-the-correct-post-test}

\begin{table}[h]

\centering

\begin{tabular}{| l | l|}
\hline
Tukey & Compare all pairs of columns \\
\hline
Bonferroni & Compare all pairs of columns OR compare selected pairs of columns \\
\hline
Dunnett & Compare all columns vs. control column \\
\hline
Trend test & Test for linear trend between mean and column number \\
\hline 
\end{tabular}
\caption{Multiple-testing adjustment methods}
\label{post-test}
\end{table}

\subsubsection{One-way ANOVA Example}

The protein expression level was measured in 5 cell types from a single cell line. We want to know whether there are any differences in the expression level between the five different cell types. The raw data are given in Table \ref{protdata}. These data come from the Babraham Bioinformatics course \href{http://www.bioinformatics.babraham.ac.uk/training.html#prism}{\color{blue}{Statistical Analysis using GraphPad Prism}}


<<echo=FALSE,results='asis'>>=
protdata <- read.csv("protein-expression.csv")
library(xtable)
xtable(protdata,label = "protdata",caption = "Protein Expression data")
@

Our \textbf{null hypothesis} is that the mean value is the same in each of the five groups.

Our \textbf{alternative hypothesis} is that the mean value is different in one or more of the five groups.

These data can be read using the \Rfunction{read.csv} function in R, which will create a \textit{data frame} representation. 
<<>>=
proteinData <- read.csv("protein-expression.csv")
@

At this point, it is a good idea to inspect the data to make sure they have been imported correctly. Sometimes R will read data without complaint, but create an object that you can't actually use for analysis. If you are using RStudio, the command \Rcode{View(proteinData)} will bring-up a display of the dataset. Otherwise the following commands will tell you about the dimensions of the data, first few lines and numerical summary of each column.

<<>>=
head(proteinData)
dim(proteinData)
summary(proteinData)
@

\subsubsection{Checking the model assumptions}

A boxplot of these data can be created using the \Rfunction{boxplot} function, which allows us to compare the median and inter-quartile range (IQR) of each cell type. Optionally, we can use the \CRANpkg{beeswarm} package to overlay individual points on the plot. See Figure \ref{fig:boxplot}

<<boxplot, fig.lp="fig:",fig.cap="Boxplot of the protein expression levels for five cell types">>=
library(beeswarm)
library(RColorBrewer)
boxplot(proteinData,xlab="Cell Type",ylab="Protein Expression",main="Protein Expression")
beeswarm(proteinData, add=TRUE,pch=16,col=brewer.pal(5,"Set1"),method="swarm")
@

\bioccomment{The \CRANpkg{RColorBrewer} package is also used to define a colour pallette for the dataset.}

Figure \ref{fig:boxplot} shows us that the median value varies between the five groups. We can also see that the data is skewed for cell types A and D, as the bar in the middle, which shows the median, is not equally between the two outer bars, which show the lower and upper quartiles. In addition, there are extreme values present for cell types C and D. We can also see that protein expression levels in some groups are much more variable than in others; the protein expression levels in group B are very consistent, but for groups C, D and E they are much more varied. 



We can make a similar assessment of the data using a histogram (plotted separately for each group in our dataset). See Figure \ref{fig:hist1}. In particular we can use these histograms to make an assessment of normality and constant variance which are two of the assumptions behind ANOVA (Section \ref{anova-assumptions}). 

<<hist1, fig.lp="fig:",fig.cap="Histogram of the protein expression levels for five cell types">>=
par(mfrow=c(2,3))
cols <- brewer.pal(5,"Set1")
hist(proteinData$A,xlab="A",col=cols[1],main="")
hist(proteinData$B,xlab="B",col=cols[2],main="")
hist(proteinData$C,xlab="C",col=cols[3],main="")
hist(proteinData$D,xlab="D",col=cols[4],main="")
hist(proteinData$E,xlab="E",col=cols[5],main="")
@

\bioccomment{If you are more-familiar with programming, you could write this chunk of code with a for loop (or similar)}

In its current format, the data are unsuitable for analysis using one-way ANOVA as both the normality assumption and the constant variance assumption are violated. We can sometimes overcome this issue by transforming the data, and in this case we can use a log-transformation to normalise the data (Note: you do not need to do this step if the assumptions of normality and constant variance hold). This can be carried out within R using the \Rfunction{log} function.

<<>>=
proteinData.ln <- log(proteinData)
head(proteinData.ln)
@

\bioccomment{If you are not sure what the \Rfunction{log} is doing, don't forget that you can bring-up the help page: \Rcode{?log}}

Hopefully the transformation will result in normally distributed data. To check this, create another histogram in the same way you did on the untransformed data (See Figure \ref{fig:hist2})

<<hist2, fig.lp="fig:",fig.cap="Histogram of the natural-log-transformed protein expression levels for five cell types">>=
par(mfrow=c(2,3))
hist(proteinData.ln$A,xlab="A",col=cols[1],main="")
hist(proteinData.ln$B,xlab="B",col=cols[2],main="")
hist(proteinData.ln$C,xlab="C",col=cols[3],main="")
hist(proteinData.ln$D,xlab="D",col=cols[4],main="")
hist(proteinData.ln$E,xlab="E",col=cols[5],main="")
@

\subsubsection{Fitting the model}

Figure \ref{fig:hist2} now shows that most of the cell types are approximately normally distributed, though cell type A is still a little questionable. We'll proceed for now, as the one-way ANOVA is quite robust to small deviations from normality, but we must bear this in mind when interpreting out results. We can also see from Figure \ref{fig:hist2} that the variance in each of the five groups is now much more similar. They do NOT need to be perfectly the same, and in this case they are similar enough for the assumption of equal variance to be reasonable. Now that we are happy that the assumptions are reasonable, we can perform the one-way ANOVA. 

When perfoming linear regression or ANOVA in R, it is more convenient to transform our data into \textbf{long} format, which can be done using the \Rcode{gather} function from the package \CRANpkg{tidyr}. For comprehensive descriptions of data manipulation and tidy data, see Hadley Wickham's paper \cite{tidyr:paper} or video \cite{tidyr:video} on the subject. 

Once we have transformed our data, the \Rfunction{aov} function fits the analysis of variance model to our data. Diagnostic plots of the model fit can be visualised using the \Rfunction{plot} function (Figure \ref{fig:anova-fit}). Of the most interest is the QQ-plot, which allows us to assess whether the distribution of the response variable should is normally distributed for each group being compared.

<<anova-fit, fig.lp="fig:",fig.cap="Visualising the results of the ANOVA model">>=
library(tidyr)
anovaData <- gather(proteinData.ln)
head(anovaData)
mod <- aov(value~ key, data=anovaData)
mod
par(mfrow=c(2,2))
plot(mod)
@

The \Rfunction{summary} function allows us to assess the significance of the model:-
<<>>=
summary(aov(mod))

@


One of the assumptions of the one-way ANOVA, which we have already explored with our scatter plot, is that the variances in each of the five groups are approximately equal. We can formally test this assumption when carrying out a one-way ANOVA, using a Bartlett's test. The results provide a p-value indicating whether equal variance can be assumed, with a value less than 0.05 suggesting that equal variance should not be assumed. 

<<>>=
bt <- bartlett.test(value~key,data=anovaData)
bt
@



In this example, the p-value was \Sexpr{round(bt$p.value,3)}, so there is no evidence to suggest that the variances in each of the five groups aren't approximately equal to each other. If the Bartlett's test gives a significant p-value, we cannot assume equal variances across the groups and a non-parametric test, such as the Kruskal-Wallis test, should be used instead of a one-way ANOVA.

The equal variance assumption is reasonable in this example, so we can go ahead and use the one-way ANOVA to analyse the data. The results of the one-way ANOVA provide a p-value of $<0.0001$ which is statistically significant. This suggests that there is evidence of a difference in the mean log-transformed protein expression levels between two or more of the five cell types. As the result of the one-way ANOVA was significant, we may be interested in making further comparisons between pairs of groups, and we can do this with the post- test results. Note: if the one-way ANOVA result had not been significant we would usually stop here and not look at the post-test results.

<<>>=
post.tests<- TukeyHSD(mod)
post.tests
@


The post-tests are actually just unpaired t-tests, but the results reported are adjusted for multiple testing. In this example, we want to compare all pairs of groups, but sometimes there may be specific groups that you wish to compare. You should plan your comparisons before starting your analysis and it is better, at least from a statistical angle, to perform the least number of comparisons that will sufficiently answer your question(s). As we want to perform more than one t-test on this data (in fact we are performing 10 pairwise comparisons!), we must be careful to adjust for multiple testing. Here we see that there is a significant difference between cell types A v D (p value: \Sexpr{post.tests$key["D-A","p adj"]}), a very significant difference between cell types B v E (p value: \Sexpr{post.tests$key["E-B","p adj"]}) and C v D (p value: \Sexpr{post.tests$key["D-C","p adj"]}), and an extremely significant difference between cell types B v D (p value: \Sexpr{post.tests$key["D-B","p adj"]}). 

Just because a result is statistically significant does not mean that it is biologically or clinically important. You can refer to the mean difference column to judge whether a difference of the seen in the data is likely to be of biological or clinical importance, but remember that these values are now on the natural log scale! You can transform back to the original scale by taking the exponential of the mean difference: in this example, the mean difference between B and D is \Sexpr{round(post.tests$key["D-B","diff"],3)} on the natural log scale. On the original scale this translates to $e^{\Sexpr{round(post.tests$key["D-B","diff"],3)}}  = \Sexpr{round(exp(1)^(round(post.tests$key["B-A","diff"],3)),3)}$.

\subsection{The Kruskal-Wallis test}
\label{kruskalWallis}

This tests if $k$ independent samples are drawn from the same population.  As the Kruskal-Wallis test ranks the values, it is more powerful than the Median test (\ref{medianTest}).  The Kruskal-Wallis test is derived from the one-way ANOVA (\ref{oneWayAnova}), but uses ranks rather than actual observations.  It is also the extension of the Mann-Whitney U test.

\subsubsection{Assumptions}

The assumptions of the Kruskal-Wallis test are:

\begin{itemize}
\item{1. The data have been collected from a randomly selected set of observations.}
\item{2. The dependent variable is at least at the ordinal level of measurement.}
\item{3. There are more than two independent groups.}
\item{4. There is independence of observations within each group and between the groups.  There are no repeated measures or multiple response categories.}
\item{5. The shapes of the distributions of the groups are similar.}
\end{itemize}

\subsubsection{Null Hypothesis}

If the last assumption holds then the hypotheses are:

$H_0$: The medians in the $k$ groups are equal.
$H_A$: There is a difference in medians between the $k$ groups.

If the last assumption does not hold:

$H_0$: The $k$ groups have the same shape and location
$H_A$: The $k$ groups have a different shape and location.

The alternative hypothesis can be directional or non-directional.  If a significant result is obtained then post hoc testing can be used to see where any differences lie. 

\subsubsection{Method}

If the assumptions are met the test can be used in the following way:

\begin{itemize}
\item{1. Determine the null and alternative hypothesis and $\alpha$ the level of significance for the test.}
\item{2. Rank the whole sample from lowest to highest.}
\item{3. Calculate the sum of the ranks for each group.}
\item{4. Calculate the average rank in each group, $R_i$, and the average rank for the whole sample,$R$ .}
\item{5. Calculate the test statistic $H$,
\begin{equation}
H = 12\frac{\sum n_i (R_i - R)^2}{N (N + 1)}
\end{equation}
where $n_i$ = the number of observations in group $i$
$N$ = the total sample size}
\item{6. Compare this value with the $\chi^2$ distribution with $k–1$ degrees of freedom.  If the statistic is bigger than the critical value in the chi-square table, the result is significant.  If the result is significant, then pairwise post hoc test can be carried out.}
\end{itemize}

\subsubsection{Example}

The data are the reduction in weekly headache activity for three treatment groups, expressed as a percentage of the baseline data (example from Altman \cite{altman}).

<<echo=FALSE,results='asis'>>=
headache <- matrix(c(62,74,86,74,91,37, 69,43,100,94,100,98, 50,-120,100,-288,4,-76), ncol=3)

colnames(headache) <- c("Relaxation / response feedback","Relaxation alone","Untreated")

print(xtable(headache),include.rownames = FALSE)
@


The null and alternative hypothesis for our test are as follows:-

$H_0$: The three samples come from populations with the same median.
$H_A$: At least one sample comes from a population with a different median.

Computing the ranks then gives the following table:

<<echo=FALSE,results='asis'>>=
N <- length(headache)
ranks <- matrix(rank(headache),ncol=3)
head.data <- data.frame("Relaxation / response feedback"=headache[,1], "Rank"=ranks[,1], "Relaxation alone"=headache[,2], "Rank" = ranks[,2], "Untreated" = headache[,3], "Rank"=ranks[,3])
head.data <- rbind(head.data, c(NA,colSums(ranks)[1], NA, colSums(ranks)[2],NA,colSums(ranks)[3]))
head.data <- rbind(head.data, c(NA,colSums(ranks)[1]/nrow(headache), NA, colSums(ranks)[2]/nrow(headache),NA,colSums(ranks)[3]/nrow(headache)))
head.data <- cbind(c(rep("", nrow(headache)),"Rank sum","(mean)"),head.data)
colnames(head.data) <- c("","Relaxation / response feedback","Rank","Relaxation alone","Rank","Untreated","Rank")
rownames(head.data) <- NULL
print(xtable(head.data),include.rownames = FALSE)

R <- (N+1)/2
R1 <- round(colSums(ranks)[1]/nrow(headache),3)
R2 <- round(colSums(ranks)[2]/nrow(headache),3)
R3 <- round(colSums(ranks)[3]/nrow(headache),3)
headache.df <- data.frame(headache)
headache.df <- gather(headache.df)
kt <- kruskal.test(value~key,data=headache.df)


@

We then have all the varaibles that we need in order to compute the test statistic

$R = \frac{N +1}{2} =  \frac{\Sexpr{N} + 1}{2} = \Sexpr{(N+1)/2}$ 

$R_1 = \Sexpr{R1}$; $R_2 = \Sexpr{R2}$; $R_3 = \Sexpr{R3}$

$H = \frac{12(\Sexpr{nrow(headache)}(\Sexpr{R1} - \Sexpr{R})^2 + \Sexpr{nrow(headache)}(\Sexpr{R2} - \Sexpr{R})^2 + \Sexpr{nrow(headache)}(\Sexpr{R3}-\Sexpr{R})^2)}{\Sexpr{N} (\Sexpr{N}+1)} = 5.69$

However, $\chi^2_{2,0.05}=5.99,5.69<5.99$. Therefore there is not sufficient evidence to reject the null hypothesis at the 5\% level of significance, $p=0.06$

\subsubsection{Analysis in R}

A quick boxplot of the raw data reveal that assumptions for a One-Way ANOVA (\ref{anova-assumptions})are not satisfied and we need to take a non-parametric approach.

<<>>=
headache <- matrix(c(62,74,86,74,91,37, 
                     69,43,100,94,100,98, 
                     50,-120,100,-288,4,-76), ncol=3)

colnames(headache) <- c("Relaxation / response feedback","Relaxation alone","Untreated")
boxplot(headache)
@

To see how to compute the statistic in R, we first have to re-format into a more convenient format using the \Rcode{gather} function from the package \CRANpkg{tidyr} package (\ref{dataManip}). We can then use the \Rcode{kruskal.test} function, which applies the kruskal-wallis test.

<<>>=
library(tidyr)
headache <- data.frame(headache)
headache <- gather(headache)
kt <- kruskal.test(value~key,data=headache)
kt
names(kt)
kt$statistic
kt$p.value
@



\subsection{Friedman's test}

The Friedman test extends the previously mentioned Wilcoxon signed ranks test to more than two repeated values at more than two time points.  Alternatively, to more than two matched groups where the individuals of each group are randomly assigned to a group.

The test examines the ranks at the different time points or matched pairs and tests whether the continuous underlying distribution of the variables is the same.  It is the non-parametric equivalent of the repeated measures ANOVA.

\subsubsection{Examples from the literature}

\begin{quote}
The Friedman test is used by Kraemer et al in their paper: “Time-of-day variations of indicators of attention: performance, physiologic parameters, and self-assessment of sleepiness” (Biol Psychiatry 2000 Dec 1; 48(11):1069-80).  The objective of this study was to analyse time-of-day variations of different indicators of attention and their interrelations.  Time-of-day variations were tested non-parametrically with Friedman's test for repeated measurements.
\end{quote}

\begin{quote}
Gustafson et al also use the Friedman test in their paper: “Effects of 4 hand-drying methods for removing bacteria from washed hands: a randomised trial” (Mayo Clin Proc 2000 Jul; 75(7): 705-8).  The objective of this study was to evaluate the effects of 4 different drying methods to remove bacteria from washed hands.  The Friedman test was used to show that there was no significant difference in the efficiency of the four methods at removing bacteria. 
\end{quote}


\subsubsection{Null Hypothesis}

$H_0$: There is no difference in median between the groups being tested.
$H_A$: There is at least one difference in median between the groups.

This is a non-directional alternative hypothesis.  If the alternative hypothesis is to be directional a more powerful way of analysing the data would be to carry out planned comparisons, with the appropriate correction for multiple testing.  Alternatively, overall tests of significance followed by post hoc tests can be used.
\subsubsection{Assumptions}

\begin{itemize}

\item{1. The data to be analysed are continuous and at least at the ordinal level of measurement.}
\item{2. The data from a randomly selected sample are either multiple observations from a single sample across more than two time periods or conditions.  Otherwise, the data are blocks of matched subjects in which the subjects from a given block are each randomly assigned to one of the three or more conditions.}
\item{3. The subjects or blocks of subjects are independent; that is, the results within one block do not have an influence on the results within the other blocks}
\end{itemize}

\subsubsection{Method}


\begin{itemize}
\item{1. Construct the null and alternative hypotheses.}
\item{2. Construct a two-way table with N (the number of subjects or matched sets of subjects) rows and k (the number of conditions or data collection periods) columns.}
\item{3. Rank each row from lowest to highest and sum ranks in each column.}
\item{4. If the null hypothesis is not true then the sum of the columns will vary from column to column.  The Friedman test examines the extent to which these column sums vary from what is expected using the following formula:
\begin{equation}
F_r = \frac{12}{Nk(k+1)}\sum_j R^2_j - 3N(k+1)
\end{equation}

where:
	$R_j$ = the sum of the ranks for column $j$
	$N$ = the number of subjects
	$k$ = the number of periods or conditions.
	}
\item{5. Look $F_r$ up in tables of Friedman’s distribution.}	
\item{6. Reject the null hypothesis in favour of the alternative hypothesis if the Fr value is greater than (or equal to) the value in the tables.}
\end{itemize}
Note: If $N$ and $k$ are sufficiently large, then $F_r$ can be compared to a $\chi^2$ distribution on $k-1$ degrees of freedom.


\subsubsection{Example}
The data for this example is taken from Rubin and Peter's paper \cite{rubinPeters}.  The Friedman test will be used to study whether or not hydralazine would relieve high blood pressure in the lungs.


<<echo=FALSE,results='asis'>>=
rubinPeters <- data.frame(Person = 1:4, Before=c(22.2,17,14.1,17), After48Hours = c(5.4,6.3,8.5,10.7), After6Months = c(10.6,6.2,9.3,12.3))
print(xtable(rubinPeters,caption="Total pulmonary resistance before and after hydralazine"),include.rownames=FALSE)

@

<<echo=FALSE>>=
rubinPeters <- data.frame(Person = 1:4, 
                          Before=c(22.2,17,14.1,17), 
                          hrs48 = c(5.4,6.3,8.5,10.7), 
                          mnths6 = c(10.6,6.2,9.3,12.3))
@


<<echo=FALSE,results='asis'>>=
N <- length(rubinPeters[,2:4])
ranks <- t(apply(rubinPeters[,2:4],1,rank))


head.data <- data.frame("Person" = rubinPeters[,1], "Before" = rubinPeters[,2], "Rank"=ranks[,1], "hrs48"=rubinPeters$hrs48,"Rank"=ranks[,2], "mths6"=rubinPeters$mnths6,Rank=ranks[,3])


head.data <- rbind(head.data, c(NA,NA,colSums(ranks)[1], NA, colSums(ranks)[2],NA,colSums(ranks)[3]))
R1 <- colSums(ranks)[1]
R2 <- colSums(ranks)[2]
R3 <- colSums(ranks)[3]

N <- nrow(rubinPeters)
k <- ncol(rubinPeters[,2:4])

#head.data <- rbind(head.data, c(NA,colSums(ranks)[1]/nrow(headache), NA, colSums(ranks)[2]/nrow(headache),NA,colSums(ranks)[3]/nrow(headache)))
#head.data <- cbind(c(rep("", nrow(headache)),"Rank sum","(mean)"),head.data)
colnames(head.data) <- c("Person","Before","Rank","After48Hours","Rank","After6Months","Rank")
rownames(head.data) <- NULL
print(xtable(head.data),include.rownames = FALSE)
fr <-  friedman.test(as.matrix(rubinPeters[,-1]))
@

$F_r = \frac{12}{\Sexpr{N} \times \Sexpr{k}(\Sexpr{k} + 1)}[\Sexpr{R1}^2 + [\Sexpr{R2}^2 + \Sexpr{R3}^2] - [3 \times \Sexpr{N}(\Sexpr{k}+1)] = \Sexpr{fr$statistic}$

As \Sexpr{fr$statistic} is the same as the value in the table there is sufficient evidence to reject the null hypothesis and conclude that at least one group is different from the others.

\subsubsection{Analysis in R}
We create a data frame representation in R, and produce the boxplot:-

<<>>=
rubinPeters <- data.frame(Person = 1:4, 
                          Before=c(22.2,17,14.1,17), 
                          hrs48 = c(5.4,6.3,8.5,10.7), 
                          mnths6 = c(10.6,6.2,9.3,12.3))
boxplot(rubinPeters[,2:4])
beeswarm(rubinPeters[,2:4],add=TRUE)
@


<<>>=
fr <-  friedman.test(as.matrix(rubinPeters[,-1]))
fr
@

\subsubsection{Post-hoc testing}
If the Friedman test shows that there is a difference in medians in the groups it is possible to carry out post hoc testing to see which groups there is actually a difference between.  This is done by comparing average ranks in all the pairs or comparing to baseline.  The null hypothesis that there is no difference in mean ranks between the pairs will be rejected if the absolute value of these differences is greater than a specified critical value.  If the following condition holds, the null hypothesis will be rejected:

\begin{equation}
|\bar{R_i} - \bar{R_j}| \geq Z_\alpha/[k(k-1)] \sqrt{\frac{k(k+1)}{6N}}
\end{equation}

where;
$R_i$ = the mean rank in period or condition $i$
$R_j$ = the mean rank in period or condtion $j$
$Z_\alpha$ = the critical $z$ value for $\alpha'$
$\alpha'$ = $\alpha/[k(k-1)]$
$k$ = the number of periods or conditions
$N$ = the number of subjects

In the example above, the average ranks for the three time points are 3, 1.25 and 1.75.  Since k= 3 and $\alpha=0.05$ critical value of the z-statistic is a z for which $\alpha'$ = 0.05 / 3(2) = 0.0083.  Looking this value up in the normal tables gives z = 2.39.  The critical value 

$2.39 \sqrt{\frac{3(4)}{6(4)}} = 1.68$

The absolute values of the three comparisons are:

$|\bar{R_1} - \bar{R_2}| = |3 - 1.25| = 1.75 > 1.68$

$|\bar{R_1} - \bar{R_3}| = |3 - 1.75| = 1.25 < 1.68$

$|\bar{R_2} - \bar{R_3}| = |1.25 - 1.75| = 0.5 < 1.68$


The comparison between before treatment and 48 hours after treatment is the only one that is greater than the critical value of 1.68.  Therefore, we can conclude that according to the post hoc approach, hydralazine only relieves high blood pressure in the lungs 48 hours after the treatment.  This effect was not maintained 6 months after treatment.

It is also possible to use the Wilcoxon ranked sign tests for post hoc testing.  The procedure is carried out in the same way as described before.  However, the Bonferroni correction must be applied to allow for multiple testing.  That is the critical value of $\alpha$ becomes $\alpha'=\alpha/k$ where k is the number of tests to be carried out and $\alpha$ is the original significance level.  The value of $\alpha'$ is the one looked at in the table or that the output p-value is compared against.

\subsubsection{Presentation of the Results}

The results of the Friedman test could be reported in the following way:

\begin{quote}
The results of the Friedman test indicate that there is a significant difference in median total pulmonary resistance across the three time periods.  Therefore, we can conclude that hydralazine alters total pulmonary resistance (p=0.042).  

Post hoc analyses with the adjustment of the two-tailed level to 0.0083 indicated that there were decreases in total pulmonary resistance from before treatment (Md=17.0) to 48 hours after treatment (Md= 7.4).  No other significant differences were found.
\end{quote}

\textbf{Note:} That post hoc testing was carried out here on a very small sample size as an illustration, in reality post hoc testing would not be carried out on such a small sample size.

\subsubsection{Advantages and Limitations}

The Friedman test is very versatile and can be used with randomised block designs and multiple observations of a single sample.  It is useful when the dependent variable is skewed.

There are some drawbacks however, it is possible for the medians not to change and there still to be significant differences between groups.  Although it is often referred to as the Friedman two-way ANOVA by ranks, it is restricted to within group comparisons.  It is not possible to test between group comparisons.  This is a major disadvantage in clinical research as it is not possible to make experimental-control group comparisons.  Each group can be analysed separately and compare their results.  However, it is not possible to test a group and time interaction with independent groups.

\subsubsection{Summary}

Friedman’s test, tests the null hypothesis that k related variables come from the same population.  For each case, the k variables are ranked from 1 to k; the test statistic is based on these ranks.  

After establishing a difference between one of the variables, post hoc testing can be carried out to decide which of the variables are actually different.  An appropriate method for allowing for multiple testing must be carried out.

\subsection{Median Test}
\label{medianTest}
Tests whether two or more independent samples are drawn from populations with the same median using the $\chi^2$ statistic.  It can be used when the assumptions of similarity of distributions for the Mann-Whitney U and Kruskal-Wallis (\ref{kruskalWallis}) tests are not met.

\subsubsection{Null Hypothesis}

$H_0$: There is no difference in medians amongst the groups being studied. 

$H_A$: There is at least one difference in medians amongst the groups being studied.

\subsubsection{Assumptions}
The assumptions of the Median test are:

\begin{itemize}
\item{1. The dependent variable is at least at the ordinal level of measurement.  The data are from 2 or more groups}
\item{2. The groups are independent and a subject can only be in one of the groups.}
\item{3. The assumptions of the $\chi^2$ test apply to the second half of the test.}
\end{itemize}

\subsubsection{Method}

If these assumptions are met then the test can be carried out in the following way:

\begin{itemize}
\item{1. Construct the null and alternative hypotheses and decide on $\alpha$ the level of significance for the test.}
\item{2. Treat the data as a single sample and calculate the overall median.}
\item{3. Separate the data into the various groups and classify the observations in each group as either above, below or equal to the overall median.  Calculate the number above and below or equal to the median, in each group.}
\item{4. Arrange these values into a $2\times c$ contingency table, where the two rows are: > or ≤ to the overall median.  The $c$ columns are the groups.}
\item{5. Calculate the $\chi^2$ statistic for the table, if the assumptions hold. }
\item{6. Compare the value of the chi-square statistic with the value in the tables on ($c-1$) degrees of freedom (where $c$ is the number of groups) at the pre-specified level of $\alpha$}
\item{7. Reject the null hypothesis of equal medians if $X^2$ exceeds the critical value of the $\chi^2$ distributions.}
\item{8. If the null hypothesis is rejected, it is then possible to do post-hoc testing on the individual groups to see which ones are significantly different.  This again will be using the median test, but applied to pairs of groups.}
\end{itemize}

\subsubsection{Example}
There are three groups with different types of dementia (data from Sanjana Nyatsanza, Fulbourn hospital).  Below are the patients’ scores on a mini mental state examination (MMSE).  The median test will be used to see if there is a significant difference between the groups.

<<echo=FALSE,results='asis'>>=
mmse <- data.frame(Group1=c(19,7,17,28,21,6,21,19,27,8,25), 
                   Group2 = c(16,22,30,24,22,23,22,28,29,29,0),
                   Group3 = c(4,9,30,29,25,22,25,26,27,18,10)
)
mmse.t <- t(mmse)
colnames(mmse.t) <- rep("",nrow(mmse))
xtable(mmse.t)
@

1. Stating the null hypothesis and significant level

$H_0$: There is no difference in medians between the groups. 

$H_A$: There is a difference in medians between the groups. 

$\alpha=0.05$

2. The overall median (i.e. the one in the middle when ranked in order) is \Sexpr{median(as.numeric(unlist(mmse)))}.

3. Classify the values in each group as above or below \Sexpr{median(as.numeric(unlist(mmse)))}.

<<echo=FALSE,results='asis'>>=
mmse.t2 <- data.frame(matrix(nrow = nrow(mmse.t)*2,ncol=ncol(mmse.t)))
mmse.t2[1,] <- mmse.t[1,]
mmse.t2[2,] <- ifelse(mmse.t[1,] > 22, ">22", "<=22")
mmse.t2[3,] <- mmse.t[2,]
mmse.t2[4,] <- ifelse(mmse.t[2,] > 22, ">22", "<=22")
mmse.t2[5,] <- mmse.t[3,]
mmse.t2[6,] <- ifelse(mmse.t[3,] > 22, ">22", "<=22")
print(xtable(mmse.t2),include.rownames = FALSE,include.colnames = FALSE)
@

<<echo=FALSE,results='asis'>>=
med <- median(as.numeric(unlist(mmse)))
class <- matrix(nrow=2,ncol=3)
class[1,] <- apply(mmse.t, 1, function(x) sum(x <= 22))
class[2,] <- apply(mmse.t, 1, function(x) sum(x > 22))
class <- cbind(class,rowSums(class))
class <- rbind(class, colSums(class))
colnames(class) <- c("Group1", "Group2","Group3","Total")
rownames(class) <- c("<=22", ">22","Total")
xtable(class)
@

5. Find the expected values for each of the cells:

<<echo=FALSE,results='asis'>>=
print(xtable(data.frame(X=c(6,5),Y=c(6,5),Z=c(6,5))),include.rownames = FALSE,include.colnames = FALSE)
@

and calculate the $\chi^2$ statistic

$\chi^2 = \sum_{ij} \frac{(O_{ij}-E_{ij})^2}{E_{ij}}$

$ = \frac{(8 -6)^2}{6} + \frac{(5 -6)^2}{6} + \frac{(5 -6)^2}{6} + \frac{(3 -5)^2}{5} + \frac{(6 -5)^2}{5} + \frac{(6 -5)^2}{5}$

$ = 0.667 + 0.167 + 0.167 + 0.8 + 0.2 + 0.2 = 2.20 $

6. The $\chi^2$ statistic for $\alpha=0.05$ is $5.99$

7. $\chi^2=2.20 < 5.99$, there is insufficient evidence to reject the null hypothesis that the medians are the same for all three groups, $p=0.33$

8. As this result is not significant, post-hoc testing could not be carried out as there are no significant differences between the groups.

The Median test has is very straightforward and easy to apply and is particularly useful when the exact values of the scores (especially those at the extremes) are unknown.  The test only considers two states for the scores, above and below (or equal to) the median and does not take the size of the differences into account.  Therefore, the Median test is less powerful than the Mann-Whitney U and Kruskal-Wallis tests.

\subsection{Analysis in R}

The median test is implemented in the \CRANpkg{RVAideMemoire} package. As usual we need to 'tidy' the input data frame (\ref{dataManip}) in order to define a factor for the test. The \Rfunction{mood.medtest} function implements the test and has the option to compute an exact, or approximate p-value.
<<>>=
library(RVAideMemoire)

mmse <- data.frame(Group1=c(19,7,17,28,21,6,21,19,27,8,25), 
                   Group2 = c(16,22,30,24,22,23,22,28,29,29,0),
                   Group3 = c(4,9,30,29,25,22,25,26,27,18,10)
)

mmse <- gather(mmse)

mood.medtest(value~key,data=mmse,exact=FALSE)

mood.medtest(value~key,data=mmse)
@


\subsection{Jonckheere-Terpstra Test}

Also known as the \textit{test for ordered alternatives} or a \textit{nonparametric test for trend}.  The Jonckheere-Terpstra test is used when the assumption that the independent variable is nominal in the Kruskal-Wallis test (\ref{kruskalWallis}) is violated i.e. the groups have an explicit order.  Since it allows the independent variable (the groups) to have an order it is more powerful than the Kruskal-Wallis test (\ref{kruskalWallis}) when the groups are ordered.  

\subsubsection{Null Hypothesis}

$H_0$: There is no difference in median values between the groups.  
$H_A$: The median values of the groups increase in a specific predetermined sequence.  

\subsubsection{Assumptions}

\begin{itemize}
\item{1. The data have been collected from a randomly selected set of observations.}
\item{2. The data to be analysed are continuous and at least at the ordinal level of measurement.}
\item{3. The $k$ groups must be ordinal with a predetermined order.}
\item{4. Under the null hypothesis it is assumed that each sample is from the same population.}
\end{itemize}

\subsubsection{Method}

\begin{itemize}
\item{1. Construct the null and alternative hypotheses and determine the level of significance, $\alpha$.}
\item{2. Specify the order of the groups, which need not be equal sized.}
\item{3. Cast the data into a two-way table with the groups in the pre-specified order, arranged from smallest to largest.}
\item{4. Within each group order the data from smallest to largest. }
\item{5. Count the total number of times each value in the first group precedes (is lower than) a value in the subsequent groups this is the precedent count for the group.}
\item{6. Add ½ to each precedent count when a tie occurs between groups.}
\item{7. Find the precedent count for the remaining groups and sum over the groups to give $J$, the test statistic.}
\item{8. Compare this value to that in the tables for $J$.  If the statistic is greater than or equal to the critical value in the Jonckheere-Terpstra test tables, the result is significant.  If the result is significant, the null hypothesis is rejected in favour of the alternative hypothesis.}
\end{itemize}

\subsubsection{Large Sample Size}

1. When the sample size is large the distribution of J tends to a normal distribution, with mean:-

\begin{equation}
\mu_j = \frac{N^2 - \sum_{j=1}^kn^2_j}{4}
\end{equation}

and standard deviation

\begin{equation}
\sigma_j = \sqrt{\frac{N^2(2N +3) - \sum_{j=1}^k n_j^2 (2n_j+3)}{72}}
\end{equation}
where,

$N$ = total sample size
$n_j$ = sample size of group $j$
$k$ = number of groups
$\sum$ = sum across groups

A $z$ statistic can then be calculated as follows:

\begin{equation}
z = \frac{J-\mu_j}{\sigma_j}
\end{equation}

This $z$ statistic can then be compared to the normal tables


\subsubsection{Example}

Mcm-2 values were collected in a breast cancer study.  The median Mcm-2 value was expected to increase with histological grade (data below).  This hypothesis was tested using the Jonckheere-Terpstra test.

<<echo=FALSE,results='asis'>>=
grade <- data.frame(Grade1 = c(1.99,3.01,4.17,7.13,9.82,9.91,NA,NA), 
                    Grade2 = c(4.40,9.82,10.23,11.99,11.99,13.17,13.20,NA),
                    Grade3 =c(6.94,8.04,9.82,15.75,18.30,25.01,26.40,28.17))
print(xtable(grade),include.rownames=FALSE)
@

Stating assumptions and significance level

1. $H_0$: The median Mcm-2 value is the same across histological grades.

$H_A$: There is an increase is median Mcm-2 value as histological grade increases.
$\alpha=0.05$

2. The order of the groups is that of increasing histological grade.

5. The precedent counts for each pair of groups is in the table below.  

6. ½ has been added to each precedent count with a tie between groups.

<<echo=FALSE,results='asis'>>=
pcounts <- data.frame(Grade1And2 = c(7,7,7,6,5.5,5,NA,"Total:37.5"),Grade1And3 = c(8,8,8,7,5.5,5,NA,41.5),Grade2And3 = c(8,5.5,5,5,5,5,5,38.5))
print(xtable(pcounts),include.rownames = FALSE)
@

7. $J = 37.5 + 41.5 + 38.5 = 117.5$

8. From the tables ($n_1=6, n_2=7,n_3=8,\alpha=0.05$) the critical value is 99. As $117.5 > 99$, there is sufficient evidence to reject the null hypothesis and conclude that there is a significant increase in median Mcm-2 value as histological grade increases.

\subsubsection{Presentation of results}

The results of the Jonckheere-Terpstra test could be reported in the following way:

\begin{quote}
The results of the Jonckheere-Terpstra test show that there is a trend for an increase in median Mcm-2 value as histological grade increases (J=117.5, p=0.003).
\end{quote}

\subsubsection{Analysis in R}

<<>>=
library(clinfun)
grade <- data.frame(Grade1 = c(1.99,3.01,4.17,7.13,9.82,9.91,NA,NA), 
                    Grade2 = c(4.40,9.82,10.23,11.99,11.99,13.17,13.20,NA),
                    Grade3 =c(6.94,8.04,9.82,15.75,18.30,25.01,26.40,28.17))
grade <- gather(grade)
grade$key <- as.numeric(gsub("Grade","",grade$key))
jonckheere.test(grade$value,grade$key)

@


\subsubsection{Advantages and limitations}

The main advantage of the Jonckheere-Terpstra test is that unlike the Kruskal-Wallis test it allows the groups to have an order therefore it is more powerful than the Kruskal-Wallis test if the groups have a pre-specified order.  Since the Jonckheere-Terpstra test is a test for trend there is no need for post hoc tests to see where differences lie after a significant result. 

The main limitation of the test is that the groups must have a pre-specified or explicit order.  It is not possible to look for an order and then test for a trend.  If there is no explicit order then a Kruskal-Wallis test should be used instead. 

\subsubsection{Summary}
The Jonckheere-Terpstra test is a more powerful alternative to the Kruskal-Wallis test when there is an explicit order to the groups.  It is a test for trend of increasing medians between the groups.  It is a much under used nonparametric test often the Kruskal-Wallis test is used where it would have been more appropriate to use the Jonckheere-Terpstra test.

\subsubsection{Summary of Several Independent Samples}

In this section, five tests for use when the independent variable has more than two groups have been covered.  The Chi-Square test and the Mantel-Haenszel test are to be used when the dependent variable is categorical.  The Median and Kruskal-Wallis tests are to be used when the dependent variable is continuous but there is no order to the groups.  The Jonckheere-Terpstra test is more powerful if there is an order to the groups. 

If the assumptions of the Kruskal-Wallis test are satisfied, it is more powerful to use this test than the Median Test.  That is the Kruskal-Wallis test is more likely to correctly reject the null hypothesis.  

\section{Regression}

\textbf{Regression Analysis} refers to a set of statistical techniques for modeling the relationship between two or more variables. One of these variables is the \textbf{response} variable (or \textbf{dependent} variable), while the other variables are known as \textbf{explanatory} (or \textbf{independent}) variables. Both response and explanatory variables are continuous, i.e. real numbers with decimal places, for example weights, intensities or growth rates.

Regression analysis is widely used for prediction, where the explanatory variables are known as \textbf{predictors} and the response variable is the thing that is being predicted.

One way of working out whether regression is the appropriate analysis for your data is to consider the most natural way of plotting the data in order to address the question you are asking. An XY scatter plot would point to regression, whereas analysis of variance (ANOVA) might be more appropriate if a better representation of the data was in the form of a box and whiskers plot.

<<scatterplot, fig.lp="fig:", fig.cap="Growth rate of E. coli at various concentrations of lactoferrin.", echo=FALSE>>=
options(digits=3)
data <- read.csv("lactoferrin.csv")
plot(data, pch=16, xlab="Concentration", ylab="Growth rate")
@

An example of a dataset where regression analysis might be applied is shown in figure \ref{fig:scatterplot}. This shows the results of a dose-response experiment where an \textit{E. coli} strain was exposed to various concentrations of the growth inhibitor, lactoferrin. In this example, we are interested in how the growth rate varies with concentration and a regression analysis would be suitable. Regression analysis involves fitting a model to the data that attempts to describe the relationship between the response and explanatory variables, in this case the growth rate and concentration.

There are several types of regression analysis \textemdash\ which you use will depend on the number of explanatory variables and the type of model to be fitted.

\begin{itemize}
\item{\textbf{Simple linear regression} \textendash\ the simplest and most frequently used, where there is one response variable and one explanatory variable and the relationship can be described through a linear model}
\item{\textbf{Multiple linear regression} \textendash\ fits a linear model using multiple explanatory variables}
\item{\textbf{Polynomial regression} \textendash\ used to test for non-linearity in a relationship}
\item{\textbf{Non-linear regression} \textendash\ to fit a specified non-linear model to the data}
\item{\textbf{Non-parametric regression} \textendash\ used when there is no obvious functional form}
\end{itemize}

\subsection{Linear Regression}

Linear regression involves fitting the simplest model of all, a linear model of the form:

\begin{equation}
y = ax + b
\end{equation}

where $y$ is the response variable and $x$ is a continuous explanatory variable. This should look familiar as the equation for a straight line graph. There are two parameters, $a$ and $b$. $a$ is the intercept, the value of $y$ when $x = 0$, and $b$ is the slope, or gradient, and is equal to the change in $y$ divided by the change in $x$ that brought about the change in $y$.

\subsubsection{The lactoferrin dataset}

Let's go back to our example dataset in figure \ref{fig:scatterplot}, showing the effect of lactoferrin concentration on the growth rate of \textit{E. coli}. We can read the data into R using the \Rfunction{read.csv} function:

<<>>=
data <- read.csv("lactoferrin.csv")
data
@

We can generate something similar to figure \ref{fig:scatterplot} using the \Rfunction{plot} function:

<<eval=FALSE>>=
plot(data$conc, data$growth, pch=16, xlab="Concentration", ylab="Growth rate")
@

Figure \ref{fig:scatterplot} shows that there is a roughly linear relationship between growth rate and lactoferrin concentration, with the growth rate decreasing with higher concentrations. We could estimate the parameters of a simple linear model by drawing a line through the data by eye and then calculating it's gradient and seeing where the line passes through the $y$-axis, i.e. the growth rate when the lactoferrin concentration is zero ($x = 0$). The R function \textbf{lm} will do this for us using a mathematical technique known as 'least squares'. Figure \ref{fig:bestfit} shows the resulting line of best fit. Also shown are the \textbf{residuals}, the vertical distances between the actual data points and the line of best fit, i.e. between the observed and fitted values.

<<bestfit, fig.lp="fig:", fig.cap="Line of best fit and residuals.", echo=FALSE>>=
with(data, plot(conc, growth, pch=16, xlab="Concentration", ylab="Growth rate"))
model <- lm(growth ~ conc,data=data)
abline(model)
fitted <- predict(model)
for (i in 1:10) lines(c(data$conc[i], data$conc[i]), c(data$growth[i], fitted[i]))
@

\subsubsection{Fitting the linear model}

The aim is to minimize the sum of squares of the residuals (also known as the error sum of squares, \textbf{SSE}), i.e. to find the minimum of

\begin{equation}
SSE = \sum(y - a - bx)^2
\end{equation}

Mathematically, we set the derivative of this function with respect to the slope to zero, do the same for the derivative with respect to the intercept, and then solve the resultant simultaneous equations. This is left as an exercise for the more mathematically inclined, or see "Statistics: An Introduction using R" by Michael Crawley \cite{crawley:statsr}.

In R, the tilde symbol, '$\sim$', is used in describing a model and can be read as 'is modelled as a function of'. In our example, the model would be written:

\begin{equation}
growth \sim conc
\end{equation}

The response variable goes on the left of the tilde and the explanatory variable on the right hand side. Our model can be read 'growth rate is modelled as a function of concentration'.

To obtain the parameters of the model, also known as the coefficients, we fit a linear model using the \Rfunction{lm} function:

<<>>=
model <- lm(growth ~ conc,data=data)
model
@

We can show the line of best fit on the plot using the \Rfunction{abline} function:

<<eval=FALSE>>=
plot(data, pch=16, xlab="Concentration", ylab="Growth rate")
abline(model)
@

and the \Rfunction{predict} function will give us the fitted values for each data point:

<<>>=
fitted <- predict(model)
fitted
@

The residuals are the differences between the observed values and the fitted values and the 

<<>>=
residuals <- data$growth - fitted
residuals
@

A noteable property of linear regression is that the line of best fit passes through the point $(\bar{x}, \bar{y})$ where $\bar{x}$ and $\bar{y}$ are the mean values of x and y respectively. 

\subsubsection{Calculating standard errors in the regression parameters}

We would like to know how reliable are our estimates for the regression parameters, i.e. the slope and the intercept. For this we consider the total variation in $y$, represented by the total sum of squares of $y$:

\begin{equation}
SSY = \sum_i(y_i - \bar{y})^2
\end{equation}

The fitted values are represented formally by the symbol $\hat{y}_i$ and the sum of squares of the residuals, SSE, can be written as follows:

\begin{equation}
\hat{y}_i = a + bx_i
\end{equation}

\begin{equation}
SSE = \sum_i(y_i - \hat{y}_i)^2
\end{equation}

Computing the SSE in R is straightforward:

<<>>=
SSE <- sum(residuals^2)
SSE
@

The total variation in $y$, $SSY$, can be partitioned into separate components for the variation that is explained by the model, denoted by $SSR$, and the unexplained variation that is the error sum of squares, $SSE$, we've already calculated.

\begin{equation}
SSY = SSR + SSE
\end{equation}

The variation that is explained by the model is called the regression sum of squares, denoted by $SSR$, is given by:

\begin{equation}
SSR = \sum_i(\hat{y}_i - \bar{y}_i)^2
\end{equation}

Although the \Rfunction{lm} function does all the hard work for you, the following shows how to compute the variances in R from our data:

<<echo=FALSE>>=
options(digits=4)
@

<<>>=
mean_growth <- mean(data$growth)
mean_growth
SSY <- sum((data$growth - mean_growth)^2)
SSY
SSR <- sum((fitted - mean_growth)^2)
SSR
SSE <- SSY - SSR
SSE
@

<<echo=FALSE>>=
error_variance <- SSE / (length(data$growth) - 2)
F_ratio <- SSR / error_variance
@

<<echo=FALSE>>=
options(digits=3)
@

\begin{table}[h]
\centering
\begin{tabular}{| l | c | c | c | c |}
\hline
\textbf{Source} & \textbf{Sum of squares} & \textbf{Degrees of freedom} & \textbf{Mean Squares} & \textbf{$F$ ratio} \\
\hline
Regression & $SSR = \Sexpr{SSR}$ & 1 & \Sexpr{SSR} & \Sexpr{F_ratio} \\
\hline
Error & $SSE = \Sexpr{SSE}$ & \Sexpr{length(data$growth) - 2} & $s^2 = \Sexpr{error_variance}$ & \\
\hline
Total & $SSY = \Sexpr{SSY}$ & \Sexpr{length(data$growth) - 1} & & \\
\hline
\end{tabular}
\caption{Anova table for the lactoferrin dataset}
\label{regression-anova-table}
\end{table}

<<echo=FALSE>>=
options(digits=4)
@


These sources of variation are laid out in an analysis of variance table in table \ref{regression-anova-table}. The mean squares column contains values for the variance for each source, calculated as:

\begin{equation}
\mathrm{variance} = \frac{\mathrm{sum\ of\ squares}}{\mathrm{degrees\ of\ freedom}}
\end{equation}

The number of degrees of freedom is determined by considering the number of parameters estimated from the data for each sum of squares. For the total sum of squares, $SSY = \sum(y - \bar{y})^2$, there is just one parameter estimated from the data: the mean value, $\bar{y}$. So we have $n - 1$ degrees of freedom, where $n$ is the number of observations (\Sexpr{length(data$growth)} in this example). Similarly, in order to calculate the error sum of squares, $SSE = \sum(y - \hat{y})^2 = \sum(y - a - bx)^2$, we need to know the values of two parameters, $a$ and $b$. These are estimated from the data, so the number of degrees of freedom are $n - 2$. The number of degrees of freedom for the regression is more difficult to understand but if we consider that the regression degrees of freedom and the error degrees of freedom should add up to the total number of degrees of freedom, then we can see that this value must be 1.

The value of most interest in table \ref{regression-anova-table} is the error variance, $s^2$.

\begin{equation}
s^2 = \frac{SSE}{n - 2}
\end{equation}

This is used in computing the standard errors in both the slope and intercept (see \cite{crawley:statsr} for the formulae).

The $F$ ratio is the ratio between the regression variance and the error variance.

<<>>=
error_variance <- SSE / (length(data$growth) - 2)
error_variance
F_ratio <- SSR / error_variance
F_ratio
@

This can be used to test for a non-zero slope in the linear regression, where the null hypothesis is that the slope is zero, i.e. there is no dependence of the response variable on the explanatory variable. The Anova table and $p$ value for the test are computed in R by calling the \Rfunction{summary.aov} function:

<<>>=
summary.aov(model)
@

\subsubsection{Summarizing the linear model}

The \Rfunction{summary} function shows the estimated slope and intercept parameters and their standard errors and is the more useful function. In practice you will not calculate the values of $SSY$, $SSE$, etc., long-hand as above, but instead just call the \Rfunction{summary} function.

<<>>=
summary(model)
@

\subsubsection{Measuring the degree of fit}

The output from the \Rfunction{summary} method includes a value for $r^2$. This is a measure of the degree of fit and is computed as the fraction of the total variation in the response variable, $y$, that is explained by the regression.

\begin{equation}
r^2 = \frac{SSR}{SSY}
\end{equation}

<<>>=
r_squared <- SSR / SSY
r_squared
@

This varies from 1 when the regression explains all of the variation in $y$ (all the observed points lie on the line of best fit, $SSR = SSY$ and $SSE = 0$) to 0 when the regression explains none of the variation ($SSE = SSY$, $SSR = 0$). The square root of this quantity, $r$, is the correlation coefficient.

\subsubsection{Checking the model assumptions}

Aside from the assumption that there is a linear relationship between the explanatory variable and the response variable, linear regression also makes the following assumptions:

\begin{itemize}
\item{\textbf{Constant variance (homoscedasticity)} \textendash\ the variance of the errors is constant across the range of values for the explanatory variable}
\item{\textbf{Normality of errors} \textendash\ the residuals follow a normal distribution}
\end{itemize}

Diagnostic plots for the model can be visualized using the \Rfunction{plot} function (figure \ref{fig:lmfitdiag}). The first graph shows the residuals plotted against the fitted values; ideally these should look random without any structure or pattern in the plot. It would be a problem if there was a clear trend of increasing scatter as the fitted values get larger, i.e. violating the assumption of constant variance. The second plot, the Q-Q plot, is also worth looking at as this can highlight problems with non-normality of errors. If the errors are normally distributed this plot should be a straight line. An S-shaped or banana-shaped plot would indicate a need to fit a different model to the data.

<<lmfitdiag, fig.lp="fig:", fig.cap="Diagnostic plots for checking the linear model fitted to the lactoferrin data.">>=
par(mfrow=c(2,2))
plot(model)
@

\subsection{Beyond Simple Linear Regression}

The above introduction to linear regression focuses solely on the simplest case of a linear relationship between a single explanatory variable and the response variable. The relationship often will turn out not to be a straight line in which case we will need to fit a non-linear model. For example, we may attempt to fit a polynomial regression model of the form:

\begin{equation}
y = a + bx + cx^2
\end{equation}

In R the model would be written as $y \sim x + x^2$

<<eval=FALSE>>=
x_squared <- x^2
quadratic <- lm(y ~ x + x_squared)
summary(quadratic)
@

Sometimes we may want to fit a model using more than one explanatory variables. Multiple linear regression involves fitting a linear model of the form:

\begin{equation}
y = a + bx_1 + cx_2 + dx_3 + ...
\end{equation}

where $x_1$, $x_2$, $x_3$, etc. are our explanatory variables. The R code for fitting this model is:

<<eval=FALSE>>=
model <- lm(y ~ x1 + x2 + x3)
@

For most non-linear models you will need to specify the exact nature of the equation as part of the model formula and use the \Rfunction{nls} function in place of \Rfunction{lm}. You will also need to supply initial guesses for each of the parameters. This can be complicated and is beyond the scope of what we cover here. See \cite{crawley:statsr} for more details.

\bibliography{stats}


\end{document}
